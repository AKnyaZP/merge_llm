{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNNuE6d1tmhN",
        "outputId": "c077f721-18c4-4349-d212-2bdbf51558cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdLSqu4mLbqz",
        "outputId": "35fabb78-d5af-43f0-b9bd-5fbe34b1b885"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo2K9t3c6jHv"
      },
      "source": [
        "Скачиваем mergekit\n",
        "Инструкция к скачиванию и документацию можно найти по ссылке:\n",
        "https://github.com/cg123/mergekit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVZX-x0jv1C3",
        "outputId": "1c83a25f-9f29-48d9-ffc3-7f66e6baf324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mergekit'...\n",
            "remote: Enumerating objects: 1100, done.\u001b[K\n",
            "remote: Counting objects: 100% (609/609), done.\u001b[K\n",
            "remote: Compressing objects: 100% (240/240), done.\u001b[K\n",
            "remote: Total 1100 (delta 473), reused 422 (delta 364), pack-reused 491\u001b[K\n",
            "Receiving objects: 100% (1100/1100), 303.24 KiB | 10.46 MiB/s, done.\n",
            "Resolving deltas: 100% (741/741), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cg123/mergekit.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsC4X8en6nsX",
        "outputId": "1427d972-13b4-4dab-977d-57f7e7adc9de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mergekit\n",
            "Obtaining file:///content/mergekit\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mergekit==0.0.4.1) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (from mergekit==0.0.4.1) (4.66.1)\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from mergekit==0.0.4.1) (8.1.7)\n",
            "Collecting safetensors==0.4.1 (from mergekit==0.0.4.1)\n",
            "  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.25.0 (from mergekit==0.0.4.1)\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==2.5.3 (from mergekit==0.0.4.1)\n",
            "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting immutables==0.20 (from mergekit==0.0.4.1)\n",
            "  Downloading immutables-0.20-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mergekit==0.0.4.1) (4.35.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from mergekit==0.0.4.1) (0.20.3)\n",
            "Collecting peft (from mergekit==0.0.4.1)\n",
            "  Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from mergekit==0.0.4.1) (4.5.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mergekit==0.0.4.1) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from mergekit==0.0.4.1) (3.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0->mergekit==0.0.4.1) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0->mergekit==0.0.4.1) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0->mergekit==0.0.4.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0->mergekit==0.0.4.1) (6.0.1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic==2.5.3->mergekit==0.0.4.1)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.6 (from pydantic==2.5.3->mergekit==0.0.4.1)\n",
            "  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions (from mergekit==0.0.4.1)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->mergekit==0.0.4.1) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->mergekit==0.0.4.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->mergekit==0.0.4.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->mergekit==0.0.4.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->mergekit==0.0.4.1) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->mergekit==0.0.4.1) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->mergekit==0.0.4.1) (2.31.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mergekit==0.0.4.1) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->mergekit==0.0.4.1) (0.15.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->mergekit==0.0.4.1) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->mergekit==0.0.4.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->mergekit==0.0.4.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->mergekit==0.0.4.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->mergekit==0.0.4.1) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->mergekit==0.0.4.1) (1.3.0)\n",
            "Building wheels for collected packages: mergekit\n",
            "  Building editable for mergekit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mergekit: filename=mergekit-0.0.4.1-0.editable-py3-none-any.whl size=9646 sha256=f127f07ee66fd84685e1e86f1504c3c4709193555d6f1ba810f760882df460fc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j2jd0tto/wheels/ed/19/4a/2c5e8cd746584b45b047bcbc1cbf1cc31ccf037775edec8120\n",
            "Successfully built mergekit\n",
            "Installing collected packages: typing-extensions, safetensors, immutables, annotated-types, pydantic-core, pydantic, accelerate, peft, mergekit\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.4.2\n",
            "    Uninstalling safetensors-0.4.2:\n",
            "      Successfully uninstalled safetensors-0.4.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.14\n",
            "    Uninstalling pydantic-1.10.14:\n",
            "      Successfully uninstalled pydantic-1.10.14\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.25.0 annotated-types-0.6.0 immutables-0.20 mergekit-0.0.4.1 peft-0.8.2 pydantic-2.5.3 pydantic-core-2.14.6 safetensors-0.4.1 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "%cd /content/mergekit\n",
        "%pwd\n",
        "#!python3 -m pip install --upgrade pip\n",
        "!pip install -e . # install the package and make scripts available\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "tyx4Z6TNfzqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMcJ-gUn9HCt",
        "outputId": "f139a617-6134-4d13-bfa5-42040a7f97e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: mergekit-yaml [OPTIONS] CONFIG_FILE OUT_PATH\n",
            "\n",
            "Options:\n",
            "  -v, --verbose                   Verbose logging\n",
            "  --allow-crimes / --no-allow-crimes\n",
            "                                  Allow mixing architectures  [default: no-\n",
            "                                  allow-crimes]\n",
            "  --transformers-cache TEXT       Override storage path for downloaded models\n",
            "  --lora-merge-cache TEXT         Path to store merged LORA models\n",
            "  --cuda / --no-cuda              Perform matrix arithmetic on GPU  [default:\n",
            "                                  no-cuda]\n",
            "  --low-cpu-memory / --no-low-cpu-memory\n",
            "                                  Store results and intermediate values on\n",
            "                                  GPU. Useful if VRAM > RAM  [default: no-low-\n",
            "                                  cpu-memory]\n",
            "  --out-shard-size SIZE           Number of parameters per output shard\n",
            "                                  [default: 5B]\n",
            "  --copy-tokenizer / --no-copy-tokenizer\n",
            "                                  Copy a tokenizer to the output  [default:\n",
            "                                  copy-tokenizer]\n",
            "  --clone-tensors / --no-clone-tensors\n",
            "                                  Clone tensors before saving, to allow\n",
            "                                  multiple occurrences of the same layer\n",
            "                                  [default: no-clone-tensors]\n",
            "  --trust-remote-code / --no-trust-remote-code\n",
            "                                  Trust remote code from huggingface repos\n",
            "                                  (danger)  [default: no-trust-remote-code]\n",
            "  --random-seed INTEGER           Seed for reproducible use of randomized\n",
            "                                  merge methods\n",
            "  --lazy-unpickle / --no-lazy-unpickle\n",
            "                                  Experimental lazy unpickler for lower memory\n",
            "                                  usage  [default: no-lazy-unpickle]\n",
            "  --write-model-card / --no-write-model-card\n",
            "                                  Output README.md containing details of the\n",
            "                                  merge  [default: write-model-card]\n",
            "  --safe-serialization / --no-safe-serialization\n",
            "                                  Save output in safetensors. Do this, don't\n",
            "                                  poison the world with more pickled models.\n",
            "                                  [default: safe-serialization]\n",
            "  --help                          Show this message and exit.\n"
          ]
        }
      ],
      "source": [
        "!mergekit-yaml --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XdrBBJZaECd"
      },
      "outputs": [],
      "source": [
        "OUTPUT_PATH = \"./merged\"  # folder to store the result in\n",
        "LORA_MERGE_CACHE = \"/tmp\"  # change if you want to keep these for some reason. /tmp it is temporary directory for temporary files, which create when we merge the models\n",
        "CONFIG_YML = \"/content/mergekit/examples/ties.yml\"  # merge configuration file\n",
        "COPY_TOKENIZER = True  # you want a tokenizer? yeah, that's what i thought\n",
        "LAZY_UNPICKLE = False  # experimental low-memory model loader\n",
        "LOW_CPU_MEMORY = False  # enable if you somehow have more VRAM than RAM+swap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgwlzq-3JzXl"
      },
      "source": [
        "In /example you can see merge_methods like Ties, Linear, SLERP and passthrough, but we can use DARE for merge two LLM's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EAmoy-R4icG"
      },
      "outputs": [],
      "source": [
        "import torch # import the torch package\n",
        "import yaml # import the yaml package, because we will need work with config.yml file\n",
        "\n",
        "from mergekit.merge import MergeOptions, run_merge # import mergekit.merge.(MergeOptions, run_merge)\n",
        "from mergekit.config import MergeConfiguration # import mergekit.config.MergeConfiguration\n",
        "\n",
        "with open(CONFIG_YML, \"r\", encoding='utf-8') as fp: # open the CONFIG_YML and encode that file in utf-8\n",
        "  merge_config = MergeConfiguration.model_validate(yaml.safe_load(fp)) # merge_config\n",
        "\n",
        "run_merge(\n",
        "    merge_config,\n",
        "    out_path=OUTPUT_PATH,\n",
        "    options = MergeOptions(\n",
        "        lora_merge_cache=LORA_MERGE_CACHE,\n",
        "        cuda=torch.cuda.is_available(),\n",
        "        copy_tokenizer=COPY_TOKENIZER,\n",
        "        lazy_unpickle=LAZY_UNPICKLE,\n",
        "        low_cpu_memory=LOW_CPU_MEMORY,\n",
        "    )\n",
        ")\n",
        "print (\"done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OdIFVSw52-sp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}